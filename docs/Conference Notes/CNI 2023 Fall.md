# CNI 2023 Fall Meeting
December 13-14, 2023 
Washington, DC.

Purpose of these notes: For Jay's own notetaking and knowledge-building purposes; to share information with others, too. 
## Opening Plenary: Clifford Lynch
[Description](https://cnifall23mtg.sched.com/event/1VHgP/opening-plenary-clifford-lynch?iframe=no)
Location: Salons I & II

### Off the top
- ==TO DO: Schedule a time to share CNI videos early in the new year.==
- A reminder to member institution reps to share information as appropriate within the institution. 
	- ==TO DO: Share these out more regularly. ==
- CNI reports -- items for further conversation 

### Infrastructure
- We are in the exascale computing age. 
	- New machines coming online - e.g. Frontier @ Oak Ridges
- Broader revisitation of what constitutes infrastructure. 
- Implications of attaching experimental equipment to broad networks
	- Carnegie Mellon University (see presentation in Dec 2021). Carnegie Mellon Universityâ€™s [Cloud Lab Project](https://cloudlab.cmu.edu/) [video]([https://www.cni.org/mm/fall-2021/plenary-sessions-f21/#cloud-lab](https://www.cni.org/mm/fall-2021/plenary-sessions-f21/#cloud-lab)
	- e.g. Self-driving labs
- Cybersecurity
	- The stats are scary -- ransomware, disruption, variety of attacks 
	- Social, critical, and cultural infrastructure under attack
	- ==TO DO: Continue and prioritize our tabletopping exercises related to restoring infrastructure after an attack.==
- Digital Twins
	- Simulation model paired with a physical model -- use both interactively to inform the other 
	- [NIST article](https://www.nist.gov/news-events/news/2023/02/how-digital-twins-could-protect-manufacturers-cyberattacks)
### AI
- It's a confusing space and incredibly lack of transparency
- All sorts of chatbots built on LLMs; everyone is using them; very few really understand how they work and exactly what the can/should be used for
	- Lots of conjecture / discussion of regulation / demoware and fake demoware 
- CNI + ARL [task force](https://www.arl.org/wp-content/uploads/2023/10/ARL-CNI-Task-Force-on-Scenario-Planning-Charge.pdf): Will share the first draft of scenarios and how they have shaped out. Hope to have a final draft by ARL meeting later in the spring. 
	- Will be helpful as a tool for institutional and community discussions. 
	- ==TO DO: Find the link==
- Key issues related to AI & ML
	- Trajectory: To a highly structure oligopoly or a patchwork of grassroots / specialized initiatives
		- Oligopoly argument: "These models are incredibly expensive to generate and run; we need big players in this space to support and monetize"
		- Counter argument: Many groups working on smaller and "smarter" models that can be more parsimonious and precise. 
	- Calls for policy and regulation 
		- Some aligning interests in the direction of oligopoly / centralization: Much easier to regulate a centralized industry; also, regulatory capture is possible when you have a few, large players. 
		- The more distributed this is, the harder it will be to regulate (e.g. the cryptography wars of the 1980s).
	- How important is generative AI vs broader portfolio of AI/ML? 
		- GAI talks to / resonates with a lot of people -- many people have to write/create things. It also threatens many who makes those things for a living 
		- National Academies' workshop in Generative AI and scientific discovery [Link](https://www.nationalacademies.org/our-work/ai-for-scientific-discovery-a-workshop)
		- Cliff's take: Generative AI will be much less important in supporting the process of discovery as it is for general public use.
	- Training data
		- Uncertain legal status of copyrighted training data
		- Liability, privacy, transparency and attribution questions. 
		- If training data is polluted by significant amounts of synthetic material (generated by GAI), then the value of the training data deteriorates rapidly
		- "Have we run out of content to feed these things?" 
		- "How stable are these models as they incorporate ongoing training via interaction?"
			- e.g. OpenAI chatbots have become worse at arithmetic as they've interacted with humans. 
		- Interactions between training model and model functionality
			- e.g., training on scholarly content (see the Allen Institute). Not a lot of results out yet. 
			- [Aurora GPT](https://wccftech.com/intel-aurora-genai-chatgpt-competitor-generative-ai-model-with-1-trillion-parameters/) - trained on scientific literature, data, code | 1 trillion parameter
	- What does it mean to be "open" in the AI space? And how do we preserve these systems?
		- Requires a nuanced set of definitions for "openness"
### Scholarly Communications
- CNI executive roundtable for RDM -- report coming out soon
- Significant increase in desire for services. Due to:
	- Funding policies, NIH data sharing policies
	- Increasing understanding from researchers that they don't know how to do this and need guidance. 
- Not sure how to do this at scale? 
	- To what extent do we teach about methods and tools? To what extent do we get involved in the process? 
	- It appears that researchers really want people getting involved in the process
- Reconsideration of the role of institutional repositories in hosting data vs. external generalist or specialized repositories 
- Success in persuading funders and open scholarship advocates that code needs to be "first-class", alongside articles and data. 
	- Rapid adoption of AI tools makes this complicated -- how to share/publish these tools? 
- Success opening up access to the scholarly record
	- Consensus on funding OA is very fragmented 
		- A lot pushback against APCs and transformative agreements 
		- Calls for entirely funder-supported infrastructure 
	- A new debate is coming related to the economic and business models 
- A new type of database -- prediction database 
	- e.g. Google Deep mind (a couple of years ago) predicting protein folds 
	- Challenge: These are predicted results (and not discovered/synthesized and validated). 
		- Requires a whole new set of scientific methods and scholarly communications processes to support. 
### Broader social/societal speculations
- The obvious: recalibrating how we assess truth in era of genAI -- we're here now.
	- The world is here. We aren't ready for it. An endless arms race between anomalies and tools to identify them. 
	- Efforts to formalize provenance through a series of digital signatures. 
		- e.g., cameras that sign the images they produce. 
		- Likely limited scope to this approach. 
		- It all comes back to trust -- do you trust the entity in charge of / operating the equipment? 
	- A role for information literacy: Teaching people about corroboration, provenance, source evaluation, etc. 
- US Copyright Office: Current position is that only humans can create; only counts if humans are using tools in a supervised way to create things 
	- Hard to know where the line is 
	- Need to rethink how we think about creators and their roles over the next 10 years. 
		- Will need to grapple with questions related to: "Who is a creator?", "What does it mean to create?" "How does ownership work in machine-generated content?"
	- Two groups/areas to think about: 
		- Creators are rightfully concerned/upset -- we underestimate in many cases how significantly this impacts their lives
		- Scholars -- How will scholars think about the use of scholarly works to train machines to synthesize and generate new information? 
	- Grappling with reanimation: If we can already make systems that can "create in the style of...", what are the implications for reanimated historical/cultural figures, family history? What does it mean when we can reanimate historical figures who can talk to you in a very convincing way about what they did and why? 
		- What does it mean when we package up our grandparents for future generations to interact with? 
### Q & A
- Other cybersecurity incidents and throughlines: Toronto Public Library (did not negotiate; still not back up and using index cards) and University of Michigan (entire university)
	- A: Qs about how robust our systems are and the priorities around what to bring back. Public-facing (communications) vs technical back-end.
		- Another eg: 23 and me breach. 
- Quantum Computing 
	- Phase-in of post-quantum / quantum-resistant technology
	- Impressive progress on computation at quantum level. 
- How to consider genAI in terms of its climate impact? 
	- Challenge 1: Realistically quantifying the impact. 
		- Training + inferencing 
			- Inferencing -- e.g. search engines coupling search results to LLMs = significant increased computational cost  
	- Challenge 2: Reconciling the urge to "throw as much compute as it as we can for the time being" vs. investing in developing more parsimonious models. 
		- Not a lot of research on cost-benefits
## 1.2 To Increase or Decrease Capacity: The What, How, and Why of 21st Century Library Skill Development
[Description](https://cnifall23mtg.sched.com/event/1VHUb/12-to-increase-or-decrease-capacity-the-what-how-and-why-of-21st-century-library-skill-development?iframe=no)  
Location: Salons D&E
### Tony Zanders (Skilltype)
- The change that we see around genAI is not new -- the 21st century has been defined by constant change
		- e.g. Library websites (2004) - Outsourced Collections (2012) - Social Justice (2016) - COVID19 (2020) - genAI (2023)
		- It's not enough to think about how we deal with genAI, but to think about how we train ourselves to manage a changing technology environm
- [Skilltype](https://www.skilltype.com/): been working on this since late 2010s
- Libraries find themselves revisiting the way they quantify and communicate their work.
- Step 1: Needs assessment: What are the priority skills and competencies for our library? 
	- Recommendations: Don't leave staff to play a guessing game -- communicate clearly the expectations for themselves 
- Step 2: Employee profiling: What skills and interests do we have? 
	- Can inform both operational and strategic work; even around whom we sponsor to attend various skill-building and learning opportunities. 
- Step 2: Talent audit: Where are our skill gaps? (i.e., what we need vs what we have?)
### Keith Webster (CMU)
- With respect to genAI, we will find new and better ways to solve the problems that have typically been our jobs 
	- But we don't need to think about this as a substitution, but an opportunity to shift tasks of professional work. 
		- e.g. what are the routine, non-complex administrative tasks that can be given to technology to make more time for the more complex work? 
	- Not mass unemployment, but mass re-deployment
- [World Economic Forum, Future of Jobs Report 2023](https://www.weforum.org/publications/the-future-of-jobs-report-2023/)
- Intersection of talent + technology = digital dexterity 
	- See the [Council of Australian University Librarians (CAUL) Digital Dexterity Framework](https://www.caul.edu.au/digital-dexterity-framework)
- Currently accelerating our work to meet the growing and changing needs related to digital research and open scholarship. 
- At CMU: Investment in people is critical 
	- Give each employee $2,500 PD fund to support conference/webinar/membership 
	- This year, set aside a separate fund for anyone who is seeking training in AI
	- Professional development coordinator -- shares training opportunities weekly 
	- Closed the Library for a day (during Fall break) for a morning of planning and experimentation + panel sessions on various topics of interest 
	- Use Skilltype
### Karim Boughida (Stony Brook U)
- Common Theme: Disconnect between library administrators and staff
	- To skills according to staff: Data, digital scholarship, etc. 
	- Top skill according to admins: "LibGuides"
- Library jobs amongst the top-20 jobs replaceable by genAI 
- What employers want: Skills, not credentials. Employers are doing skills-based hiring
- **PD always a priority -- never cut it from the budget** 
### Q&A
- Developing skills in current staff vs. addressing gaps/limitation in current MLIS education
	- It's important to acknowledge that the principles of information management and arrangement are always going to be relevant, but very few indiividuals in the future will need to know how to catalogue a book, specifically. 
- What about "decreasing capacity" -- where might we decrease capacity? 
	- "decreasing capacity" is not about removing people -- it's about reprioritizing where they do their work.
	- In the very long term, the Library may end up with fewer people, but with greater specialized expertise (more expensive). 
- Libraries are no longer the primary provider of scholarly content -- gives us an opportunity to provide other important services 
	- Change from collections-based organization to a service-based organization. 
- Dept of Labour: Estimates 7% increase in information professionals by 2030. 
### Thoughts
- A lot to think about in terms of our current state and trajectory with skills development within the Library.
- We need a fuller strategy for staff development 
## 2.1 Models for Sustainable and Inclusive Data Science Consulting and Collaboration in Higher Education
[Description](https://cnifall23mtg.sched.com/event/1VHVS/21-models-for-sustainable-and-inclusive-data-science-consulting-and-collaboration-in-higher-education?iframe=no)  
Location: Salons I & II  
Emily Griffith and Mara Blake  

- At NC State 
	- Data science-related programs 
		- Multiple coordinated avenues of support
			- Dept of stats 
			- Libraries data and viz services 
			- Data Science Academy 
		- Goals: 
			- Not duplicating efforts 
			- Seamless access for users 
- Data and Viz Services 
	- Consulting; Workshops & Instruction; Specialized Spaces
		- Staff for consulting: librarians, gradudate student consultants (8-10 students), staff data science support specialist
		- Service: 30-minute consultation time (appointments) for support and guidance (not production)
			- Drop in or scheduled | In-person or virtual
- DSA Services 
	- Fills gap with medium-sized projects that are too big for DVS. 
		- Wrangling data, analyzing, visualization (don't do discovery or software access)
	- Graduate student staff + one faculty director
	- Support: 
		- Up to 20 hours of dedicated data science support peer project (no long-term projects)
- Collaborating between CVS and DSA 
	- Complementary services 
	- Shared intake and triage
	- Joint student hiring process 
	- Regular meetings and communications
	- Grants and projects to advance data science consulting as a subfield
- Consulting models 
	- 1-year project with a cohort of experts 
	- Goal: identify options to structure data science consulting (admin locations, funding, staffing, retention, training, etc.)
- Preliminary takeaways
	- Structure = dynamic and engaged groups 
	- Lots of good work being done 
	- **A lot of services are customized to local contexts and needs**
- Forthcoming 
	- Special issue of journal **Stat**
	- Upcoming grant project - supporting presentations and conferences to share the project work + publication that outlines how to leverage graduate student employees in a consulting program (i.e., manual with job postings).
		- ==TO DO: Flag for the DASH program.==  
- Q&A
	- Which disciplines are being supported through this program? 
		- Computer science, engineering, natural resources, statistics, economics; very interdisciplinary in terms of users; Also hire inline with interdisciplinary needs.
	- Who is sponsoring the DSA? A: Provost 
	- Assessment and quantifying ROI
		- Keep track of appointments / projects 
		- It's really not that expensive to hire graduate students 
		- Focus on educational experience for the students 
## 3.2 Partnerships in Research and Data Services: High Performance Computing, Collocation, and Facilitation
[Description](https://cnifall23mtg.sched.com/event/1VHVt/32-partnerships-in-research-and-data-services-high-performance-computing-collocation-and-facilitation?iframe=no)  
Location: Salons D&E
### Michael Navicky & Lauren Geiger (Mississippi State University)
- Using the [RCDCM](https://carcc.org/rcdcm/). Potential uses: 
	- user it as an in-depth SWOT (Strength, Weaknesses, Opportunities, Threats) chart
	- Comparison with peer institutional capabilities 
	- Collaboration potentials within own institution. 
- Mississippi State University and RCDCM 
	- Using existing models and frameworks to build a team of people to support HPC services 
	- Running successful HPC is more than just the computers 
	- > Insert photo of slide
	- System-facing coverage 
	- When they got to the data-facing capabilities, realized that they just didn't know what was available. 
		- Reached out to the Library -- led to fruitful conversations. RCDCM proved to be an opportunity for collaboration. 
- MSU Research Team
	- HPC
		- strengths = Data storage, computational capability and knowledge, systems 
	- MSU Libraries 
		- strengths = RDM (description, visualization), service-oriented, well connected 
	- IT Services (cyberinfrastructure)
	- Office of Research (compliance and funding) 
	- Researchers (needs drive services) 
- Challenges 
	- Departments are siloed; limited access to software, storage, compute; limited staff to train/support; recognizing the value of Research Computing and Data (RCD)
- Approach 
	- Build relationships around RCDCM 
	- Discover researcher needs 
	- Build systems and support staff capabilities 
	- Communicate with senior leaders, faculty and researchers about long-term value of RCD
### Jason A. Clark & Doralyn Rossmann (Montana State Research Alliance)
- [MS Research Alliance](https://www.montana.edu/research-alliance/)
- ![[Pasted image 20231211164646.png]]
- They did the RCDCM as well. -- focused on researcher- and data-facing roles 
- People don't care who you are and where you come from: They just want to find people that can help them. 
- Researcher Alliance 
	- Floated 10 years previous as a Library hub
	- Secure funding and space allocation - housed in the Library
	- Worked with Rebecca Bryant from OCLC
- Partners
	- Office of Research Development 
	- Centre for Faculty Excellent (Provost)
	- Undergraduate Scholars Program 
	- Research Infrastructure 
	- MS Library (Their research data services unit is called ROADS--not confusing at all)
- Vision: Bring together expertise to help researchers meet goals 
	- Better proposals... (Need to get the rest)
- Co-location has led to "good collisions"
	- A lot more faculty coming into the Library
	- Promotes social interoperability 
	- "It's intentional work to connect" - being together in the same space provides the intentionality.
- What they did to make it work 
	- MOU -- especially around the in-person stuff (it's kind of like being roommates)
	- Move from virtual to in-person partnerships 
	- Defining services and communications 
	- Naming, signage
	- Communication channels: Email list, reservable spaces 
- Used the RCDCM to identify areas of weakness
	- Outcomes from the RCDCM helpful when speaking with University admins, because it is benchmarked against other institutions 
	- Doing the exercise helped them understand what the partnerships and activities should be. 
- Research Optimization, analytics, and data services (ROADS)
	- Open Ed theory and practice
	- Schol Comms and publishing
	- (see slides for rest)
- Activities 
	- ![[Pasted image 20231211165848.png]]
- Shared projects resulting from collaboration 
	- ![[Pasted image 20231211165823.png]]
### Q&A: 
- What are the resources required to complete the RCDCM assessment and computing the results? 
	- Mississippi: "Finding the data" to complete the assessment was tough and took some time, but if you can get in contact with the right people, it's very doable. 
	- Challenge is getting the proper stakeholders to participate 
		- Understanding what people want and helping to meet those needs. 
	- Montana: Quite grass-roots; done as a means of brining better notice to the Provost / President
- How are peoples' FTEs distributed? 
- How is success defined? 
	- Montana State has metrics defined for success.
	- Cataloging outreach and engagement. Mine data about service partnerships. 
### Notes to self / Takeaways  
- ==Q: Interested in the questions/pressures that you've had from upper university administrators about return on investment==
- ==How to integrate Research Offices folks more into the DRCP? How to make them active participants? ==
- ==**RSD team: Role in supporting data science / AI?**==

## Lightning Round
[Description](https://cnifall23mtg.sched.com/event/1VHVt/32-partnerships-in-research-and-data-services-high-performance-computing-collocation-and-facilitation?iframe=no)  
Location: Salons I & II
### Presentation 1
- [Cyberinfrastructure to Support the Scalable Exchange of Sensitive and Proprietary Usage and Impact Metrics Across Public and Private Stakeholders](https://www.cni.org/topics/assessment/cyberinfrastructure-to-support-the-scalable-exchange-of-sensitive-and-proprietary-usage-and-impact-metrics-across-public-and-private-stakeholders), Christina Drummond, University of North Texas
- [OA Book User Data Trust Effort](https://www.oabookusage.org/) 
- [International data spaces](https://internationaldataspaces.org/)
### Presentation 2
- [LEADING Next Steps: Evaluating the Sustainability and Impact of Post-graduate Professional Development and Mentorship Programs](https://www.cni.org/topics/economic-models/leading-next-steps-evaluating-the-sustainability-and-impact-of-post-graduate-professional-development-and-mentorship-programs), Erik Mitchell, University of California, San Diego
- A lot of important benefits, but sustainability as a key challenge for these kinds of programs
	- How might libraries collaborate to innovate professional education that impacts recruitment, growth, and retention? 
### Presentation 3
- [Ecosystem for Next Generation Infrastructure (ENGIN)](https://www.cni.org/topics/ci/ecosystem-for-next-generation-infrastructure), Sayeed Choudhury, Carnegie Mellon University
- Infrastructure  = technology + humans (human-centred engineering)
- Open source + open science as drivers of next-gen infrastructure 
- [CMY Cloud Lab](https://cloudlab.cmu.edu/) - anyone with an internet connection and computer can access HPC resources
- Provocative question: What does genAI do to CC-BY?
### Presentation 4
- [The Research Data Support Landscape: Findings from a National Inventory of University Services](https://www.cni.org/topics/repositories/the-research-data-support-landscape-findings-from-a-national-inventory-of-university-services), Dylan Ruediger, Ithaka S+R
- > NOTE: Could look at this survey as a potential service mapping basis? 
- ![[Pasted image 20231211174150.png]]
- ~70% of services in R1 and R2 are consultation-based services (as opposed to training-based services)
	- Introduces questions around scaling 
- Libraries as the primary provider, but many other offices are offering services, tools 
	- Med school, IT, research office, etc. 
- Findings published in early 2024. 
	- Will include detailed breakdown with Canadian context, and mapping between disciplines and providers. 
### Presentation 5
- [The Stacks Platform: A System for Onsite Access to Rights Restricted Digital Content at the Library of Congress](https://www.cni.org/topics/special-collections/the-stacks-platform-a-system-for-onsite-access-to-rights-restricted-digital-content-at-the-library-of-congress), Trevor Owens, Library of Congress
### Presentation 6
- [Unexpected Opportunities Illuminated by Yaleâ€™s LUX Project](https://www.cni.org/topics/special-collections/unexpected-opportunities-illuminated-by-yales-lux-project), Robert Sanderson, Yale University
- LUX: Unified digital access to collections of libraries, museums and archives (across all of Yale)
- Built on Linked Open Data 
- Other uses
	- Using knowledge graphs beyond collections -- e.g. to discover relevant research datasets
	- Benefits from describing core university functions (e.g. restaurants, student services) 
	- Use the data to build non-hallucinating AI
- Cleaning code -- will come to GitHub soon. 
### Presentation 7
- [LIBER - Association of European Research Libraries](https://www.cni.org/topics/digital-libraries/liber), Julien Roche, LIBER
- Wide range of activities, from networking to learning and training, to open resources 
- Leadership programs 
	- Emerging Leaders | Library Directors
- [International projects](https://libereurope.eu/projects/) 
	- ![[Pasted image 20231211175816.png]]

## 4.1 Navigating the Artificial Intelligence-Driven Academic Frontier: Tools and Initiatives
Location: Salons I & II  
[Description](https://cnifall23mtg.sched.com/event/1VHip/41-navigating-the-artificial-intelligence-driven-academic-frontier-tools-and-initiatives?iframe=no)  
### Joelen Pastva (CMU)
- Motivation: Increase pathways for users to discover library resources
- Researchers don't regularly start looking at the Library catalogue/website -- how to help them find what they need?
- [keenious](https://keenious.com/) - recommender tool (powered by AI) to assist in discovery of relevant scholarly articles by analyzing text inputs
- Questions / concerns
	- Data sources -- uses open sources: openalex, unsub, unpaywall 
	- Algorithmic transparency 
	- Assessment options
	- User and data privacy 
	- Impact on research process 
	- Product roadmap 
	- Keenious passed all concerns, but requires regular revisitation to ensure the values/objectives/business models do not drift toward misalignment.
- ![[Pasted image 20231212090033.png]]
- Outcomes 
	- User retention increased, more clicks through to the link resolver 
### Ben Shaw (U of Maryland)
- Impetus: Uncertainty around understanding of generative AI; application by learners and instructors
- Intervention: [Canvas module](https://bit.ly/AI-ELMS) that can be integrated into courses, or serves as standalone module 
- Goals 
	- IL gaps, conversations about plagiarism, not alienating students, easy to integrate into other instructional materials, practical skills (not bound to any particular tool or discipline)
- Methods 
	- Conversations with faculty, students 
- Contents: 
	- Basics of AI tools (mechanics; bias, labour, privacy)
	- Fact-checking (common errors; lateral reading exercises)
	- Citation styles 
	- Resources to explore further
- Module: https://bit.ly/AI-ELMS 
- If interested in using, email bshaw1@umd.edu
### Leo Lo (UNM)
- ==TO DO: Contact Leo to get framework==
- Impetus: How to get people to use and engage with a new tool like genAI? 
- Intervention: 12-week program
- Goals: 
	- Enhance capabilities, find practical applications 
	- Develop proficiency, hands-on skill development 
	- Seed innovation, create a culture open to experimenting with and adopting new technologies proactively 
- Had get-togethers with participants to discuss learning 
- The "Explorers" - participants 
	- 10 interdisciplinary professionals, mix of skill levels 
- Outcomes 
	- Did a pre/post-program survey 
	- Increase in familiarity and literacy and confidence
	- Program itself rated highly 
	- ![[Pasted image 20231212090750.png]]
- ![[Pasted image 20231212090725.png]]
- Key Learnings 
	- Prompt practice **built critical skills**
- Challenges 
	- Data privacy concerns 
	- Prompt engineering difficult by essential
	- AI lacked subject matter expertise
### Elias Tzoc (Clemson)
### Q&A 
- Keenious: Draws from OpenAlex, but restricts the articles it pulls from (e.g. only English), results in about 50M articles (which is still pretty good). What is trajectory for the product?
## 5.1 Researcher and Institutional Impact of Data Management and Sharing Policies
[Description](https://cnifall23mtg.sched.com/event/1VHj7/51-researcher-and-institutional-impact-of-data-management-and-sharing-policies?iframe=no)  
Location: Salons I & II  
- ==TO DO: RDM Team to review Outcomes of [Realities of Academic Data Sharing (RADS) Initiative](https://www.arl.org/realities-of-academic-data-sharing-rads-initiative/) ==
- Data sharing requirements have gotten increasingly complex in the US. 
- Research questions: 
	- How do institutions support research data management and sharing? 
	- How do researchers prepare and share research data? 
	- What is the institutional cost to implement mandated public access to research data policies? 
- Considerations  
	- Created a common framework to compare across different universities with different structures 
		- Service categories
		- Libraries, IT, Research, Institutes & Centres
	- Created a common set of data sharing activities 
	- Creating a model for estimating data sharing costs 
- How they engaged with stakeholders
	- Admins: Surveys + follow-up focus groups
	- Researchers: IDed in specific subject areas, having received specific relevant grants 
- Results 
	- ==TO DO: Look for report in Jan 2024==
	- 27 RDM and sharing activities identified 
	- ==TO DO: Check out the frameworks and visualizations on the project page. e.g.: https://public.tableau.com/app/profile/mollie.webb/viz/rads_data_support_activities_service_centers/rads_ic ==
	- ![[Pasted image 20231212093833.png]]
	- ![[Pasted image 20231212093848.png]]
 - ![[Pasted image 20231212094021.png]]
- ![[Pasted image 20231212094836.png]]
- Takeaways 
	- Researchers are doing the majority of data sharing activities on their ownership 
	- Researchers have **always had to manage their data** -- the shift is how to prepare it for others to find, use 
	- (missed a point here -- check slides later)
	- Many service/support units stull adjusting to changing requirements (compliance-based, minimizing risk, etc.)
	- Library services are generally focused on needs of the researcher , but researchers perform a lot of these themselves 
		- May not know about it
		- May assume Libraries don't have expertise
		- Libraries may not have capacity to support all project 
		- May not be empowered 
- Opportunities 
	- For IT: Data security services. Creating QC mechanisms or procedures for infrastructure 
	- For central research offices: Ensure finding agency requirements for data sharing have been met 
	- For research institutes / spec centres: 
		- May not be available to provide outside services, but may serves as models for providing services (pilot projects)
	- For Libraries 
		- Assisting with decision-making on sharing
		- Selecting / applying licenses for reuse 
		- Adopting PIDs 
	- Cross-campus collaboration 
		- Recommendations, policies, and practices for deaccessioning/removind data 
		- IDing and budgeting for the costs of data management and sharing 
		- Training / education 
- Some examples of cross-campus collaborations 
	- Michigan - Research
	- Duke
	- Cornell 
### Q&A
- When researchers say "I did this myself, how much of this was a graduate student?"
- Grant was an excellent opportunity to have conversation across units 
## 6.2 A Radical New Approach to Data Citation: Cook the Carrots, Burn the Sticks
[Description](https://cnifall23mtg.sched.com/event/1VQvA/62-a-radical-new-approach-to-data-citation-cook-the-carrots-burn-the-sticks?iframe=no)  
Location: Salons D & E  
- Relevant links: 
	- [Make Data Count](https://makedatacount.org/data-citation/)
	- [Previous presentation](https://zenodo.org/records/10083792) 
	- [DataCite dashboard](http://corpus.stage.datacite.org/dashboard)
#### [Jamie Wittenberg](https://cnifall23mtg.sched.com/speaker/jamie.wittenberg1 "Jamie Wittenberg")
- We don't know how data can be found. If we're not capturing metadata about data use, we're not counting it. 
- Questions: 
	- Who uses data and for what purposes? 
	- What is the impacrt of open data, for policy making, research, etc.? 
- The data citation problem 
	- Datasets sent from DataCite to Crossref -- 5.6M
	- Datasets declared by publishers (via Crossref) to DataCite datasets -- 7,600. 
- Moving away from "carrots and sticks" model 
	- We know there are lots of carrots 
	- We know there are lots of sticks: data sharing policies / compliance requirements at institutions for data storage and retention. 
	- But they don't seem to work very well!
- What is we could step back from this approach, take the burden off of researchers, and take advantage of machines to build these relationships, whether the relationships are explicit or not? 
### [John Chodacki](https://cnifall23mtg.sched.com/speaker/johnchodacki "John Chodacki")
- Make Data Count 
	- Community effort to ensure dataare used and cited in open, transparent, and responsible ways
		- Build open infrastructure and community-based standards 
1. Community best practices 
2. Adopt best practices 
3. Contextualize best practices 
4. Use data metrics to enable evaluation
5. Incentivize researchers to use.
- Metrics: Views, downloads, citation 
	- Citation is a challenge, but also something that researchers value 
- Challenges: Looking for data citations 
	1. People: Researchers not incentivized to cite data 
	2. Technologies: information needs to propagate through various systems -- requires mediation from various stakeholders and organizations. (repo-publisher-crossref-datacite)
	3. Ecosystem: Citations that do not make it to PID metadata | Many approaches out there to identify data citations
- Global Data Citation Corpus
	- Incorporate data citations from PID metadata deposit workflows + additional sources that aggregate or discover citations through various techniques (ML, full-text processing)
		- Chan Zuckerberg Initiative (CZI) is contributing data citations identified through the CZI Knowledge Graph, which mines the text of publications via a machine-learning algorithm
- Corpus prototype 
	- define "datasets" --> Apply ML model to corpus (SciBERT)--> Extract dataset mentions --> link to a repository 
### [Kristi Holmes](https://cnifall23mtg.sched.com/speaker/kristiholmes2 "Kristi Holmes")
- Most important part is that it is collaborative. Solving this problem requires many groups working together. 
- Libraries as interconnective tissue. Bringing together a variety of stakeholders, contextualizing. 
- How to stay informed | how to get involved 
	- ![[Pasted image 20231212104511.png]]
	- Make data count community meeting in Fall 2024
	- Paper coming out in March 2024 - Harvard data science review special edition 
- [Joint Statement on Research Data ](https://datacite.org/blog/joint-statement-on-research-data/)
- NIH-funded project around 
## 7.2 Bringing Digitized Special Collections into the Research Workflow through JSTOR: Outcomes of a Three-year Pilot
[Description](https://cnifall23mtg.sched.com/event/1VQve/72-bringing-digitized-special-collections-into-the-research-workflow-through-jstor-outcomes-of-a-three-year-pilot?iframe=no)
Location: Salons D & E


## 8.2 Duke University's Research Support Initiative: Assessment, Recommendations, and Implementation
[Description](https://cnifall23mtg.sched.com/event/1VQwV/82-duke-universitys-research-support-initiative-assessment-recommendations-and-implementation?iframe=no)  
Location: Salons F & G
#### [John Board](https://cnifall23mtg.sched.com/speaker/john.board "John Board")
#### [Tim McGeary](https://cnifall23mtg.sched.com/speaker/tim.mcgeary "Tim McGeary")
#### [Rebecca Brouwer](https://cnifall23mtg.sched.com/speaker/rebecca.brouwer "Rebecca Brouwer")
- About 2 years ago: CIO revisited how OIT supported research computing from top to bottom 
	- How do we support the non-HPC crowd? 
	- Especially in the Social Sciences and Humanities who have few resources? 
	- Meeting new data management requirements 
	- Managing digital storage 
	- Challenge of having separate IT structures on campus and the health system 
- First stop: IT Governance 
	- 90 minutes, bi-weekly: IT Advisory Council (15 faculty members + U/G + GS + senior IT leadership from OIT + schools)
	- Solicited more comprehensive solicitation of faculty opinions on research support -- 50 more faculty in 7 working groups were added to discuss emerging IT support needs for research across the University.
- 4-phase process: 
	- Phase 1: Assess needs (faculty-driven)
	- Phase 2: Propose solutions (service-partner driven)
	- Phase 3: Determine structures (institutionally-determined)
	- Phase 4: Implementation (service partner driven)
- Phase 1
	- ![[Pasted image 20231212132109.png]]
	- ==Main feedback: Not so much about IT, but "Where is the subject-matter expertise to help me navigate all of the things in the way of the work I want to do"==
	- ![[Pasted image 20231212132117.png]]
	- Outputs: https://itac.duke.edu/resource/research-it-needs/
	- "We need teams of domain-specific technical people who can engage with specialists in different areas and map their problems/needs onto existing (or prospective) solutions."
	- "Everything is interconnected; everything depends on everything. This is a university-wide problem to solve (OIT, OVPR, UL)
	- ![[Pasted image 20231212133036.png]]
- Phase 2: Propose solutions (service-partner driven)
	- 3 co-sponsors as leaders
	- ![[Pasted image 20231212133044.png]]
	- Participants asked to prioritize interventions -- mapped alongside sponsor strategic priorities
	- ![[Pasted image 20231212163426.png]]
	- ![[Pasted image 20231212133403.png]]
- Looking to add 15-20 FTEs across units 
- ![[Pasted image 20231212133416.png]]
- ![[Pasted image 20231212133500.png]]
 - Phase 3 
	 - Convened planning team of financial leads and sponsor reps 
	 - Identify workable ongoing funding options for each prioritized service 
		 - e.g. charge to grants, philanthropy, allocations-funded, etc.
	 - Develop multi-year funding/walkup plans including, as needed, bridge funding 
	 - Ensure sponsor backing 
	- Types of positions being added 
		- ![[Pasted image 20231212133825.png]]
	-  Types of services
![[Pasted image 20231212133947.png]]
- Phase 4: 
	- Implementation working group - member from each co-sponsoring unit 
	- Begin planning around virtual teams to engage school-level resources and central units 
	- Prioritize hiring: Develop JDs
	- Explore how/where to connect other services from provisers 
	- Determine metrics: Demand, capacity, and success 
	- Determine added "governance structures" as may be needed. 
	- Services already in development: 
		- ![[Pasted image 20231212134427.png]]
 - Takeaways 
	 - Some of our issues are likely common to others 
	 - Some issues are unique to schools with medical centres 
	 - ==***Faculty input coupled with leadership engagement and service provider expertise is critical to enhancing research support services***==
### Q&A
- From when did this start -- Feb 2022. See more information in [session description](https://cnifall23mtg.sched.com/event/1VQwV/82-duke-universitys-research-support-initiative-assessment-recommendations-and-implementation?iframe=no)
- Invaluable individuals: Those who are able to translate knowledge between disciplinary and technical spaces. Able to interact with researchers/faculty, understand their questions, map it to solutions and workflows. 

## Closing Plenary: Open Access, Open Scholarship, and Machine Learning: A Panel and Community Conversation
[Description](https://cnifall23mtg.sched.com/event/1VQwx/closing-plenary-open-access-open-scholarship-and-machine-learning-a-panel-and-community-conversation?iframe=no)
Location: Salons I & II

### Introduction by Cliff
- Advocates for open science have traditionally had a clear motivation: To allow universal access to information to gain knowledge and build upon it. 
	- All of this has been navigated through complex legal and ethical structures. 
	- Open Access/Scholarship has benefited considerably from technology and computing advancement--has made it considerably easier to connect and share information.  
	- People were generally comfortable with computational mining / text analysis / network and citation analyses 
	- But with the rise of genAI tools, people don't seem to be as sure how they feel about this technology--it's a step further than the things we traditionally were comfortable with. 
	- There are also many complexities associated with legal ambiguity of training genAI models with copyrighted/human-generated material. 

### [Heather Sardis](https://cnifall23mtg.sched.com/speaker/sardis "Heather Sardis") (MIT)

### [Rachael Samberg](https://cnifall23mtg.sched.com/speaker/rsamberg "Rachael Samberg")(UC Berkeley)
- Copyright is a complex landscape, and there are rarely clear and universal interpretations.
- But there are 2 precepts that should hold: 
	1. Training AI is a fair use, particularly in research and scholarship context. Important to protect this as essential to these activities and this enterprise.
		- Rights to recreate corpora for research purposes or create derivative products for research have been preserved repeatedly. 
		- This type of use does not supplant the commercial 
		- Important distinction between training AI vs. AI outputs 
			- Mechanics of genAI outputs poorly understood. 
			- Many cases where the outputs may infringe upon the original works from which the models were created. 
	2. Scholars' ability to access original works to train AI should not be precluded. Full stop. 
		- TDM often requires use of massive datasets, including copyright owners who cannot be identified or unwilling to grant rights -- if opt-out for AI training was permitted, scholarship would be impeded. 
			- It could also lead to new licensing models, where content is re-licensed for use in AI training. 
- Merely preserving fair use rights for AI training is not enough. Need to pursue lawmakers to change the legal frameworks that allow publishers to control access to works for these purposes. 

### [Richard Sever](https://cnifall23mtg.sched.com/speaker/richard_sever.1uynytf8 "Richard Sever")(Cold Spring Harbor Laboratory Press)
- Inclined to use the term "universal access" instead of "open access". 
	- Purpose is to facilitate geometric growth in research and innovation -- by both humans and machines. 
- See TDM falling clearly within fair use, but want to keep authors in control and in support, as well.
	- e.g., using genAI to provide lay summaries of works. Some authors disagreed with machine-generated summaries (but many human-generated summaries face disagreement, too)
### Q1
Scholarly arguments that train genAI with scholarly content is an ethical risk. 
- Desire for opt-outs. 
- Concerns about bolstering already large corporate players in this space. 
How should we address these kinds of issues? 
- If our interest is to provide open and universal access, it is not our role to then say who can and should use these materials. However, regulation is key to ensure that  
	- Focusing on pro-worker and pro-human legislation
		- [AI needs to be more â€˜pro-worker.â€™ These 5 policies can help](https://mitsloan.mit.edu/ideas-made-to-matter/ai-needs-to-be-more-pro-worker-these-5-policies-can-help) 
		- Alignment and deeper review of [CARE principles ](https://www.gida-global.org/care)
- Scholarly and creative works are already used in all sorts of ways by members of society (by humans and not just machines). This is part of the deal of creating a scholarly or creative work. 
	- But, this doesn't mean that researchers shouldn't engage in ethical practices that are mindful and respectful to the content creators.  
- [EU approach to AI](https://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence)
	- Use for research and scholarship is enshrined and opt-out does not apply; opt-out applies for commercial activities. 
- Thinking about infrastructure 
	- e.g. thinking about infrastructure rights in a similar way to water rights, to ensure that everyone has access to it. 
	- e.g. We don't want a system where only billion-dollar companies can create data and train models. 

### Q2
Should we think about scholarly literature differently than other types of media (books, movies, magazines, etc.)?
How to think about peer reviewed vs. non-peer reviewed (e.g. preprints)

- The notion of distinguishing clearly between peer-reviewed and non-peer reviewed 
is naive and disingenuous -- there is a wide range of quality in both.
	- Who is the arbiter of "good"? 

- Shouldn't differentiate, but should have clear regulations how tools should be used and how products can/should be shared. 

- From a technical standpoint, there is not much difference -- everyone is scooping up and ingesting everything amidst this hype cycle. What we should be thinking about is **"How to make it as easy as possible to access good scholarly content?"**. 

### Q3
Pragmatics and scale: What kind of infrastructure we need? What kind of choices we should be making to ensure these machines-driven tools provide a net benefit and that they are transparent in terms of their methods? 

- "Do we need a new CC license to facilitate responsible training?"
	- CC licenses do not override exceptions like fair use. Training AI with copyrighted content is permitted regardless. 
	- In terms of disclosing information sources (attribution), CC licenses already afford reasonableness from an attribution perspective (allows variety of means of attribution). 
	- Role for Libraries is around education. Right now, the onus is on researchers to determine whether or not what they want to do is lawful and ethical. This inhibits their research. 
		- Also around advocacy to ensure we get the right laws that allows researchers to do their work when they are making a good-faith effort to comply with ethical and legal requirements on their activities. 
